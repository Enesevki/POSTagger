# CRF TabanlÄ± TÃ¼rkÃ§e CÃ¼mle Ã–ÄŸesi Etiketleme (POS Tagging)

Bu proje, TÃ¼rkÃ§e metinler iÃ§in **KoÅŸullu Rastgele Alanlar (Conditional Random Field - CRF)** tabanlÄ± bir CÃ¼mle Ã–ÄŸesi Etiketleme (Part-of-Speech Tagging) modeli geliÅŸtirmek, eÄŸitmek ve analiz etmek iÃ§in kapsamlÄ± bir araÃ§ seti sunar. Projenin temel amacÄ±, bir kelime dizisi verildiÄŸinde her kelimeye ait dilbilgisel rolÃ¼ (`NOUN`, `VERB`, `ADJ` vb.) doÄŸru bir ÅŸekilde atamaktÄ±r.

CRF, Ã¶zellikle POS tagging gibi sÄ±ralÄ± veri etiketleme gÃ¶revleri iÃ§in gÃ¼Ã§lÃ¼ bir modeldir Ã§Ã¼nkÃ¼ bir kelimenin etiketini tahmin ederken sadece o kelimenin Ã¶zelliklerine deÄŸil, aynÄ± zamanda Ã§evre kelimelerin etiketlerine ve Ã¶zelliklerine de bakar. Bu sayede cÃ¼mlenin bÃ¼tÃ¼nÃ¼ndeki baÄŸlamÄ± daha etkili bir ÅŸekilde yakalar.

<br>

## âœ¨ Temel Ã–zellikler

Bu proje, bir makine Ã¶ÄŸrenmesi modelinin yaÅŸam dÃ¶ngÃ¼sÃ¼ndeki kritik adÄ±mlarÄ± yÃ¶netmek iÃ§in tasarlanmÄ±ÅŸ modÃ¼ler araÃ§lar iÃ§erir:

-   **Veri YÃ¶netimi**: Ham `.conll` formatÄ±ndaki veriyi okuma, yazma ve standart EÄŸitim/GeliÅŸtirme/Test setlerine ayÄ±rma.
-   **Ã–zelleÅŸtirilebilir Model EÄŸitimi**: L1 (`c1`) ve L2 (`c2`) dÃ¼zenlileÅŸtirme gibi kritik hiperparametreleri ayarlayarak modeller eÄŸitme.
-   **KapsamlÄ± Hiperparametre DeÄŸerlendirmesi**: K-katmanlÄ± Ã‡apraz DoÄŸrulama (K-Fold Cross-Validation) ile bir model mimarisinin genelleme performansÄ±nÄ± gÃ¼venilir bir ÅŸekilde Ã¶lÃ§me.
-   **Ã–ÄŸrenme Potansiyeli Analizi**: Ã–ÄŸrenme ve Hata EÄŸrileri (`learning_curve`, `error_curve`) Ã§izerek modelin veri miktarÄ±na olan duyarlÄ±lÄ±ÄŸÄ±nÄ±, aÅŸÄ±rÄ±/eksik Ã¶ÄŸrenme (overfitting/underfitting) eÄŸilimlerini analiz etme.
-   **Derinlemesine Nihai Model Analizi**: EÄŸitilmiÅŸ bir modelin "karnesini" Ã§Ä±karma:
    -   DetaylÄ± SÄ±nÄ±flandÄ±rma RaporlarÄ± (Precision, Recall, F1-score).
    -   GÃ¶rselleÅŸtirilmiÅŸ KarmaÅŸÄ±klÄ±k Matrisleri (Confusion Matrix).
    -   SÄ±nÄ±flandÄ±rma gÃ¼venini Ã¶lÃ§en ROC EÄŸrileri ve AUC skorlarÄ±.
    -   Modelin "beynini" anlamak iÃ§in en Ã¶nemli Ã¶zellik ve geÃ§iÅŸlerin listesi.
    -   HatalÄ± tahmin edilen Ã¶rnekler iÃ§in detaylÄ± bir rapor.

<br>

## ğŸ“‚ Proje Mimarisi ve Dosya AÃ§Ä±klamalarÄ±

Proje, her birinin net bir sorumluluÄŸu olan betik ve modÃ¼llerden oluÅŸur. Bu yapÄ±, kodun anlaÅŸÄ±labilirliÄŸini ve bakÄ±mÄ±nÄ± kolaylaÅŸtÄ±rÄ±r.

```
pos_tagger_crf/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ stanza_tagged_output_3200     # Ä°ÅŸlenmemiÅŸ tÃ¼m verinin birleÅŸimi
â”‚   â”‚   â””â”€â”€ stanza_tagged_output_1600
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ train.conll         # EÄŸitim seti
â”‚       â”œâ”€â”€ dev.conll           # GeliÅŸtirme/doÄŸrulama seti
â”‚       â””â”€â”€ test.conll          # Test seti
â”‚       â””â”€â”€ test_300Ssentences.txt  # 300 cÃ¼mlelik Test seti
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ training_analysis/      # Ã–ÄŸrenme eÄŸrisi gibi eÄŸitim analizi Ã§Ä±ktÄ±larÄ±
â”‚   â”œâ”€â”€ model_analysis/         # Nihai model analizinin Ã§Ä±ktÄ±larÄ±
â”‚   â”œâ”€â”€ diagnose_v2/            # Modeli script iÃ§inde Ã¼retip kaydetmeden deÄŸerlendirme yapmak iÃ§in
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ crf_final.pkl       # EÄŸitilmiÅŸ ve kaydedilmiÅŸ model
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py          # Veri okuma, yazma ve bÃ¶lme iÅŸlemleri
â”‚   â”œâ”€â”€ features.py             # CÃ¼mlelerden Ã¶zellik Ã§Ä±karma mantÄ±ÄŸÄ±
â”‚   â”œâ”€â”€ model.py                # CRF modelini oluÅŸturma ve eÄŸitme fonksiyonlarÄ±
â”‚   â”œâ”€â”€ utils.py                # YardÄ±mcÄ± fonksiyonlar (JSON/pickle kaydetme vb.)
â”‚   â”œâ”€â”€ train.py                # Model eÄŸitimi ve hiperparametre deÄŸerlendirme betiÄŸi
â”‚   â””â”€â”€ analyze_model.py        # EÄŸitilmiÅŸ bir modelin detaylÄ± analizi iÃ§in betik
â”‚   â””â”€â”€ diagnose_v2.py          # Modeli kaydetmeden kendi iÃ§inde eÄŸiterek anlÄ±k detaylÄ± analiz iÃ§in betik
â”‚
â”œâ”€â”€ requirements.txt            # Proje baÄŸÄ±mlÄ±lÄ±klarÄ±
â””â”€â”€ README.md                   # Bu dosya
```

| Dosya AdÄ±          | AÃ§Ä±klama                                                                                                                                              |
| :----------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------- |
| `data_loader.py`   | `.conll` formatÄ±ndaki veriyi okur, yazar ve train/dev/test setlerine bÃ¶ler. Bu betik, veri hazÄ±rlÄ±ÄŸÄ± iÃ§in bir komut satÄ±rÄ± aracÄ± olarak kullanÄ±labilir. |
| `features.py`      | Bir cÃ¼mledeki kelimelerden CRF modelinin kullanacaÄŸÄ± Ã¶zellikleri (`word shape`, `suffix`, `prefix`, baÄŸlam vb.) Ã§Ä±karan fonksiyonlarÄ± iÃ§erir.              |
| `model.py`         | `sklearn-crfsuite` kÃ¼tÃ¼phanesini kullanarak CRF modelini inÅŸa etme, eÄŸitme ve yÃ¼kleme gibi temel modelleme fonksiyonlarÄ±nÄ± barÄ±ndÄ±rÄ±r.                  |
| `utils.py`         | JSON/Pickle dosyalarÄ±nÄ± kaydetme/yÃ¼kleme, klasÃ¶r oluÅŸturma gibi genel yardÄ±mcÄ± fonksiyonlarÄ± iÃ§erir.                                                   |
| **`train.py`** | **Model GeliÅŸtirme BetiÄŸi.** Hiperparametreleri test etmek (CV), Ã¶ÄŸrenme eÄŸrilerini Ã§izmek ve nihai modeli eÄŸitmek iÃ§in kullanÄ±lÄ±r.                      |
| **`analyze_model.py`** | **Model Analiz BetiÄŸi.** Ã–nceden eÄŸitilmiÅŸ bir `.pkl` modelinin performansÄ±nÄ± derinlemesine analiz etmek ve raporlamak iÃ§in kullanÄ±lÄ±r.                   |
| **`diagnose_v2.py`** | **Model TanÄ±lama BetiÄŸi.** Model kaydetmeden betik iÃ§inde eÄŸitilip performansÄ±nÄ± derinlemesine analiz etmek ve raporlamak iÃ§in kullanÄ±lÄ±r.                   |
| `requirements.txt` | Projenin Ã§alÄ±ÅŸmasÄ± iÃ§in gereken Python kÃ¼tÃ¼phanelerini listeler.                                                                                      |

<br>

## ğŸ’¾ Veri Seti

Bu projede kullanÄ±lan veri seti, yaklaÅŸÄ±k 3200 cÃ¼mleden oluÅŸmaktadÄ±r. Bu veri setinin yarÄ±sÄ± (1600 cÃ¼mle) proje kapsamÄ±nda tarafÄ±mÄ±zca manuel olarak hazÄ±rlanmÄ±ÅŸtÄ±r. DiÄŸer yarÄ±sÄ± ise iki farklÄ± akademik veri setinin birleÅŸiminden elde edilmiÅŸtir:

1.  **English/Turkish Wikipedia Named-Entity Recognition and Text Categorization Dataset**: TÃ¼rkÃ§e Wikipedia'dan otomatik olarak etiketlenmiÅŸ cÃ¼mlelerden oluÅŸan bir koleksiyon.
    > *Åahin, H. BahadÄ±r; Eren, Mustafa Tolga; TÄ±rkaz, Ã‡aÄŸlar; SÃ¶nmez, Ozan; YÄ±ldÄ±z, Eray (2017), â€œEnglish/Turkish Wikipedia Named-Entity Recognition and Text Categorization Datasetâ€, Mendeley Data, V1, doi: 10.17632/cdcztymf4k.1*

2.  **Compilation of Bilkent Turkish Writings Dataset**: Bilkent Ãœniversitesi'nin TÃ¼rkÃ§e 101 ve 102 derslerinde 2014'ten bu yana Ã¶ÄŸrenciler tarafÄ±ndan oluÅŸturulan yaratÄ±cÄ± yazÄ± metinlerinden oluÅŸan bir derleme.
    > *YÄ±lmaz, Selim F. (2025), â€œCompilation of Bilkent Turkish Writings Datasetâ€, Zenodo, V2, doi: 10.5281/zenodo.15498155*

<br>

## ğŸš€ Kurulum

Projeyi yerel makinenizde Ã§alÄ±ÅŸtÄ±rmak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± izleyin.

1.  **Sanal Ortam OluÅŸturun (Ã–nerilir)**: Proje baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± sisteminizdeki diÄŸer paketlerden izole etmek iÃ§in bir sanal ortam oluÅŸturun.
    ```bash
    python -m venv venv
    source venv/bin/activate  # macOS/Linux iÃ§in
    # venv\Scripts\activate    # Windows iÃ§in
    ```

2.  **BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin**: Projenin ana dizinindeyken `requirements.txt` dosyasÄ±nÄ± kullanarak gerekli tÃ¼m kÃ¼tÃ¼phaneleri yÃ¼kleyin.
    ```bash
    pip install -r requirements.txt
    ```

<br>

## ğŸ› ï¸ KullanÄ±m ve AdÄ±m AdÄ±m Ä°ÅŸ AkÄ±ÅŸÄ±

Bu proje, en iyi sonuÃ§larÄ± elde etmek iÃ§in yapÄ±landÄ±rÄ±lmÄ±ÅŸ bir iÅŸ akÄ±ÅŸÄ± sunar.

### AdÄ±m 1: Veri HazÄ±rlama

Bu adÄ±m, projenin en baÅŸÄ±nda yalnÄ±zca bir kez yapÄ±lÄ±r. TÃ¼m verinizi iÃ§eren bÃ¼yÃ¼k bir `.conll` dosyasÄ±nÄ±, modelin eÄŸitimi ve deÄŸerlendirmesi iÃ§in standart setlere ayÄ±rÄ±n.

```bash
python -m src.data_loader --input data/raw/all_data.conll --outdir data/processed
```
> Bu komut, `data/processed/` klasÃ¶rÃ¼ne `train.conll`, `dev.conll` ve `test.conll` dosyalarÄ±nÄ± oluÅŸturur. **Test seti (`test.conll`) modelin performansÄ±nÄ± en son Ã¶lÃ§eceÄŸimiz, dokunulmaz veridir.**

### AdÄ±m 2: Model GeliÅŸtirme ve Hiperparametre Optimizasyonu

Bu aÅŸamada `train.py` betiÄŸini kullanarak model mimarinizi test eder ve en iyi hiperparametreleri ararsÄ±nÄ±z.

**a) HÄ±zlÄ± Performans DeÄŸerlendirmesi (Cross-Validation)**

FarklÄ± `c1` ve `c2` deÄŸerlerinin genelleme performansÄ± Ã¼zerindeki etkisini hÄ±zlÄ±ca gÃ¶rmek iÃ§in `--mode evaluate_hparams` kullanÄ±n.

```bash
# c1=2.0 ve c2=2.0 deÄŸerlerini 5-katmanlÄ± CV ile test et
python -m src.train --mode evaluate_hparams --data data/processed/train.conll --c1 2.0 --c2 2.0
```
> Bu komut, verilen hiperparametreler iÃ§in K-katmanlÄ± Ã‡apraz DoÄŸrulama Ã§alÄ±ÅŸtÄ±rÄ±r ve konsola ortalama F1 skorunu basar. Bu iÅŸlemi farklÄ± `c1`, `c2` deÄŸerleri iÃ§in tekrarlayarak en iyi kombinasyonu bulmaya Ã§alÄ±ÅŸÄ±n.

**b) AÅŸÄ±rÄ±/Eksik Ã–ÄŸrenme Analizi (Learning Curve)**

SeÃ§tiÄŸiniz bir hiperparametre setinin davranÄ±ÅŸÄ±nÄ± daha detaylÄ± anlamak iÃ§in Ã¶ÄŸrenme eÄŸrilerini Ã§izin.

```bash
# c1=2.0 ve c2=2.0 iÃ§in Ã¶ÄŸrenme ve hata eÄŸrilerini Ã§iz
python -m src.train --mode learning_curve --data data/processed/train.conll --c1 2.0 --c2 2.0
```
> Bu komut, `outputs/training_analysis` klasÃ¶rÃ¼ne grafikler oluÅŸturur. **Grafikteki eÄŸitim ve doÄŸrulama Ã§izgileri arasÄ±ndaki bÃ¼yÃ¼k bir fark, aÅŸÄ±rÄ± Ã¶ÄŸrenmeye (overfitting) iÅŸaret eder.**

### AdÄ±m 3: Nihai Modelin EÄŸitimi

En iyi performansÄ± verdiÄŸine karar kÄ±ldÄ±ÄŸÄ±nÄ±z hiperparametrelerle nihai modelinizi eÄŸitmek iÃ§in `--mode train` kullanÄ±n. Bu komut, eÄŸitim verisinin tamamÄ±nÄ± kullanarak tek bir model eÄŸitir ve kaydeder.

```bash
python -m src.train --mode train --data data/processed/train.conll --out-model outputs/models/crf_final.pkl --c1 2.0 --c2 2.0 --verbose
```
> Bu komutun Ã§Ä±ktÄ±sÄ±, `outputs/models/crf_final.pkl` dosyasÄ±nda saklanan, projenizin nihai Ã¼rÃ¼nÃ¼dÃ¼r.

### AdÄ±m 4: Nihai Modelin KapsamlÄ± Analizi

ArtÄ±k eÄŸitilmiÅŸ bir modeliniz var. `analyze_model.py` ile bu modelin "karnesini" Ã§Ä±karÄ±n. Bu betik, **sadece ve sadece** `--model` ile verdiÄŸiniz `.pkl` dosyasÄ±nÄ± analiz eder.

```bash
python -m src.analyze_model --model outputs/models/crf_final.pkl --train data/processed/train.conll --test data/processed/test.conll --output-dir outputs/final_model_analysis
```

Bu komutun sonucunda:
* **Konsolda** modelin genel parametrelerini, Ã¶ÄŸrendiÄŸi en Ã¶nemli kurallarÄ± (geÃ§iÅŸler ve Ã¶zellikler) ve hem eÄŸitim hem de test setleri iÃ§in detaylÄ± performans raporlarÄ±nÄ± gÃ¶rÃ¼rsÃ¼nÃ¼z.
* **`outputs/final_model_analysis` klasÃ¶rÃ¼nde** ise bu analizlerin kaydedilmiÅŸ hallerini (JSON raporlarÄ±, PNG grafikleri, CSV hata listesi) bulabilirsiniz.

<br>

## ğŸ“ˆ Gelecek Ã‡alÄ±ÅŸmalar ve Ä°yileÅŸtirme FÄ±rsatlarÄ±

Bu proje saÄŸlam bir temel sunsa da, performansÄ± daha da artÄ±rmak iÃ§in potansiyel iyileÅŸtirme alanlarÄ± mevcuttur:

* **GeliÅŸmiÅŸ Ã–zellik MÃ¼hendisliÄŸi**: TÃ¼rkÃ§e'nin morfolojik zenginliÄŸinden faydalanmak iÃ§in `features.py`'a kelimenin kÃ¶kÃ¼ (lemma), hal ekleri, iyelik ekleri gibi daha detaylÄ± dilbilimsel Ã¶zellikler eklenebilir.
* **Hiperparametre Optimizasyon AraÃ§larÄ±**: En iyi `c1` ve `c2` deÄŸerlerini manuel olarak aramak yerine `Optuna` veya `Scikit-learn`'in `GridSearchCV` gibi araÃ§larÄ±nÄ± entegre ederek bu sÃ¼reci otomatikleÅŸtirmek.
* **FarklÄ± Algoritmalar**: `sklearn-crfsuite`'in sunduÄŸu farklÄ± optimizasyon algoritmalarÄ±nÄ± (`lbfgs` yerine `l2sgd`, `ap`, `pa` gibi) denemek.
* **Kelime VektÃ¶rleri (Word Embeddings)**: Ã–zellik setine `Word2Vec` veya `FastText` gibi Ã¶nceden eÄŸitilmiÅŸ kelime vektÃ¶rlerini dahil ederek modelin kelime anlamlarÄ±nÄ± daha iyi yakalamasÄ±nÄ± saÄŸlamak.
